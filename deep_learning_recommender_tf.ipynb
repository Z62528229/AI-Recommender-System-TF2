
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ccda213f-debb-4fa1-9b72-8f10c112b3fe",
     "kernelId": ""
    },
    "id": "1zKrxVlfnqvM"
   },
   "source": [
    "# Deep Learning Recommenders in TensorFlow\n",
    "\n",
    "Dr. Nick Ball  \n",
    "Data-Scientist-in-Residence, Paperspace\n",
    "\n",
    "Last updated: Nov 12th 2021\n",
    "\n",
    "This self-contained notebook shows the use of Paperspace Gradient to implement a recommender system using TensorFlow. It accompanies the 6-part blog series \"Gradient End-to-End: A Recommender System using Notebooks and Workflows\" on the [Paperspace blog](https://blog.paperspace.com), and the associated [Git Repository](https://github.com/gradient-ai/Deep-Learning-Recommender-TF).\n",
    "\n",
    "The project includes these main highlights:\n",
    "\n",
    "1. Show a real-world-style example of machine learning on Gradient\n",
    "2. End-to-end dataflow incorporating both Gradient Notebooks and Workflows\n",
    "3. Modern data science methodology based on Gradient's integrations with Git\n",
    "4. Use TensorFlow 2 and TensorFlow Recommenders (TFRS) to train a recommender model that includes deep learning\n",
    "5. Use training data that reflects what real-world projects deal with (not just demo data)\n",
    "6. Construct a custom model using the full TensorFlow subclassing API\n",
    "7. Show working hyperparameter tuning that improves the results\n",
    "8. Deploy model using Gradient Deployments and its TensorFlow Serving integrations\n",
    "9. Accompanying material: self-contained working Jupyter notebook, and Git repository\n",
    "10. Aimed at a broad technical audience: data scientists who are not engineers, engineers who are not data scientists, those who span the two disciplines, and others\n",
    "\n",
    "The project is not a complete enterprise-grade recommender system: they would typically take teams of several people months to construct, and result in an amount of code far greater than shown here, but it aims to be more than just a simple demonstration or toy model, by showcasing real data science techniques. In the Appendix we discuss some of the steps one might take to go from the project here to a full system, with a focus on Gradient's capabilities.\n",
    "\n",
    "We assume the reader of this notebook is somewhat technical, but not necessarily an expert in recommender systems, deep learning, TensorFlow, or Paperspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1c6661f1-13d8-4a0c-a567-2f68f08a5bdc",
     "kernelId": ""
    }
   },
   "source": [
    "## Note: Section 5 is coming soon!\n",
    "\n",
    "Model deployment support in the Gradient product on public clusters is currently pending, expected in Sept. 2021. Therefore section 5 of the Notebook on model deployment is shown but will not yet run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b53f6968-20b4-499e-9cec-e491c4e37097",
     "kernelId": ""
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "The notebook is designed to run on Paperspace Gradient\n",
    "\n",
    " - In the Gradient GUI, create a Project with a name, e.g., Deep Learning Recommender\n",
    " - Within the project, create a Notebook with the following settings:\n",
    "   - Don't select any of the boxes under Select a runtime\n",
    "   - Select a machine = C4 (C5, P4000, etc., will also work)\n",
    "   - Public/private = set to preferred option\n",
    "   - Under Advanced options:\n",
    "     - Set the Workspace URL field to https://github.com/gradient-ai/Deep-Learning-Recommender-TF to point to this repository.\n",
    "     - Set the Container name field to `tensorflow/tensorflow:2.4.1-gpu-jupyter`\n",
    "     - Set the Container command to `jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.trust_xheaders=True --NotebookApp.disable_check_xsrf=False --NotebookApp.allow_remote_access=True --NotebookApp.allow_origin='*'`\n",
    "     - The other options can remain the same.\n",
    " - Start the Notebook\n",
    "\n",
    "Once the Notebook has started, click `deep_learning_recommender_tf.ipynb` to run in the usual way by clicking Run under each cell in turn.\n",
    "\n",
    "Notebook creation can also be done on the command line if desired, via gradient notebooks create. For more details on Notebooks, see the documentation.\n",
    "\n",
    "Alternatively, you can clone the Git repository and run in your own notebook setup\n",
    "\n",
    " - `git clone https://github.com/gradient-ai/Deep-Learning-Recommender-TF.git` (the repo is public, so Git's ssh command form is not required)\n",
    " - Be able to run Python 3, and import modules as in Section 2 below: Matplotlib, NumPy, TensorFlow 2, TFDS, TFRS\n",
    " - We use some notebook cell magic lines, such as `%matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5b638cdd-222a-4188-953b-e15a349b64a2",
     "kernelId": ""
    }
   },
   "source": [
    "### Additional requirements to run Gradient Workflows and model deployment (sections 4.3+)\n",
    "\n",
    "In addition to the above, to run the Gradient Workflows in section 4.3 and the model deployment in section 5 requires some more setup.\n",
    "\n",
    "This step is optional:\n",
    "\n",
    " - Use or create a [Gradient Private Cluster](https://docs.paperspace.com/gradient/gradient-private-cloud/about/setup/managed-installation) and [get its ID](https://docs.paperspace.com/gradient/gradient-private-cloud/about/usage#finding-your-cluster-id). If no cluster ID is specified, the Gradient public cluster will be used.\n",
    "\n",
    "These requirements will remain, being associated with Workflows as the enterprise-grade production part of Gradient:\n",
    "\n",
    " - [Create a project](https://docs.paperspace.com/gradient/get-started/managing-projects#create-a-project) and [get its ID](https://docs.paperspace.com/gradient/get-started/managing-projects#get-your-projects-id)\n",
    " - [Generate an API key](https://docs.paperspace.com/gradient/get-started/quick-start/install-the-cli#obtaining-an-api-key) for your project to allow access\n",
    " - [Store the API key](https://docs.paperspace.com/gradient/get-started/managing-projects/storing-an-api-key-as-a-secret) as a secret in your project\n",
    "\n",
    "These steps will go away as the product matures around Workflows:\n",
    "\n",
    " - [Create the two workflows](https://docs.paperspace.com/gradient/explore-train-deploy/workflows/getting-started-with-workflows#creating-gradient-workflows) named `recommender-train-model` and `recommender-deploy-model`, and [get their IDs](https://docs.paperspace.com/gradient/explore-train-deploy/workflows/getting-started-with-workflows#running-your-first-workflow-run)\n",
    " - [Create an output dataset](https://docs.paperspace.com/gradient/data/data-overview/private-datasets-repository#creating-a-dataset-and-dataset-version) for the training workflow, named `recommender`\n",
    " \n",
    "The create workflow step and create output dataset can be done via the GUI, or the [command line interface](https://docs.paperspace.com/gradient/get-started/quick-start/install-the-cli) (CLI). The commands for the latter look like\n",
    "\n",
    "`gradient storageProviders list --apiKey <your API key>` \n",
    " \n",
    "Note the `storage provider ID` for **Gradient Managed** storage.\n",
    "\n",
    "`gradient datasets create --name recommender --storageProviderId <your storage provider ID> --apiKey <your API key>`  \n",
    "`gradient workflows create --name Recommender-Train-Model --projectId <your project ID> --apiKey <your API key>`  \n",
    "`gradient workflows create --name Recommender-Deploy-Model --projectId <your project ID> --apiKey <your API key>`\n",
    "\n",
    "The usage of `--apiKey` on the command line is optional: you can also store a key in a JSON file, e.g., `~/.paperspace/config.json` to avoid having to add it to each command. Here we leave it present. Another option is the environment variable `PAPERSPACE_API_KEY`. See [connecting your account](https://docs.paperspace.com/gradient/get-started/quick-start/install-the-cli#connecting-your-account) for more details.\n",
    "\n",
    "Note that one thing that is *not* required for this project is any setup on your own machine, unless you choose to use the CLI. This is because the Workflows are invoked from this Notebook, via the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "080fde46-2160-4aef-82f2-6cd9ceec9a92",
     "kernelId": ""
    }
   },
   "source": [
    "### Format of notebook text\n",
    "\n",
    "The main text is shown as MarkDown, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "73b20b1b-b9c4-4454-a715-7068f7a48f81",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional extra information is in cell comments, like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "17f2ea5b-5a7b-4590-b3d1-fb11f08d4754",
     "kernelId": ""
    }
   },
   "source": [
    "### Recommenders\n",
    "\n",
    "Recommender systems are widely used in modern artificial intelligence, most prominently in retail and entertainment content. However, many of these systems in businesses still use classical methods such as matrix factorization that may not capture all of the information now available.\n",
    "\n",
    "The addition of the fully nonlinear mappings allowed by machine learning, for example deep learning neural network layers, can improve the performance of recommender systems by both capturing more of the complex patterns of information that are present, and by making it easier to add new information in the form of further data feature columns, such as detailed text descriptions or reviews, multiple user and item information columns, or timestamps.\n",
    "\n",
    "Here, we use the new TensorFlow Recommenders library to show how the addition of deep learning to a recommender model improves its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "185f3b48-0dca-441c-8c34-7d5fd0a5e9ce",
     "kernelId": ""
    },
    "id": "VAsFUrkgyYAu"
   },
   "source": [
    "# Contents\n",
    "\n",
    "1. Introduction: Recommender systems and deep learning\n",
    "2. Setup\n",
    "3. Preparing the dataset\n",
    "4. Build the recommender models\n",
    "5. Deploy the final model\n",
    "6. Conclusions\n",
    "\n",
    "Next Steps  \n",
    "Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f4b12273-0446-4da1-96cf-8868d3dd1d3f",
     "kernelId": ""
    },
    "id": "tnDTzpDQ_hUS"
   },
   "source": [
    "## 1: Introduction: Recommender systems and deep learning\n",
    "\n",
    "A good way to describe most recommender systems is:\n",
    "\n",
    "*Present suggested new items to a user that users similar to them already liked.*\n",
    "\n",
    "This is on the assumption that if users similar to them liked something, there is a better-than-random chance that they will like it too.\n",
    "\n",
    "The short sentence above involves several concepts, including information about a user, how to measure if they are similar to another user, what items the other users liked, how to choose candidate items to present from the whole list, and how to rank those choices.\n",
    "\n",
    "(There are further ideas as well, such as whether a user rated an item explicitly or just implicitly liked it by watching or buying it, and using other similarities such as item-item as well as user-user similarity.)\n",
    "\n",
    "Here, we use the well-known MovieLens dataset, containing information about which movies users watched, along with details of the movies, the users, and the times of viewing. The idea is to present to a user suggested movies that they might like to watch next.\n",
    "\n",
    "While not a huge modern dataset with millions of viewings from millions of users, it has been widely used, and is \"real enough\" to show both how deep learning can improve recommender models, and how to set up and end-to-end data science workflow.\n",
    "\n",
    "The content of this notebook is based on the tutorials of the [TensorFlow Recommenders (TFRS) library](https://www.tensorflow.org/recommenders), modified to include more real-world data science steps, and showing a model being deployed into production.\n",
    "\n",
    "As described there, recommender models commonly consist of two parts:\n",
    "\n",
    " - Retrieval, which selects possible candidates from the whole list of items that could be recommended, in this case being movies the user might be interested in\n",
    " - Ranking, which narrows down this list to a refined set of items to recommend\n",
    "\n",
    "We concentrate on the ranking portion, showing how the addition of deep learning layers, data features, and hyperparameter tuning, improves the performance of the model.\n",
    "\n",
    "We then show how the resulting model can be easily deployed with Gradient Deployments.\n",
    "\n",
    "The concentration on just one part of the models to be built is so that we can show more fully realized data science steps, the end-to-end process using both Gradient Notebooks and Workflows, and some of the corresponding functionaity, without the project becoming overly long or repetitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cd8dc7dd-a9be-421a-a3ea-1414e9c6c096",
     "kernelId": ""
    },
    "id": "3EeRY5DQI5VV"
   },
   "source": [
    "## 2: Setup\n",
    "\n",
    "This project uses [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets) and the TensorFlow Recommenders library (TFRS) in addition to the basic TensorFlow 2 and Python 3.\n",
    "\n",
    "TFRS was created as a separate library because recommender systems typically do not correspond to the simple setup of supervised learning models, but have a more complex arrangement of processing steps associated with them. So rather than using a few layers in the high-level TensorFlow Keras Sequential or [Functional](https://www.tensorflow.org/guide/keras/functional) APIs, they need the custom model and custom layer setup in the lower level representation of writing the model classes and subclasses directly.\n",
    "\n",
    "However, recommenders do contain their own common components, such as the FactorizedTopK performance metric for retrieval, that mean usage of a library is considerably more convenient than writing something from scratch in TensorFlow.\n",
    "\n",
    "We use TensorFlow Datasets as the emphases in this project are recommenders, Gradient functionality, end-to-end, and showing some model tuning, rather than data gathering, cleaning, and preparation. Of course, in a full enterprise system this would be a more prominent aspect of the dataflow.\n",
    "\n",
    "Let's install TFDS, TFRS, and import these and the Python modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "dbe8232b-9934-495c-87cd-55f403afc2b2",
     "kernelId": ""
    },
    "id": "9gG3jLOGbaUv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.4\n",
      "    Uninstalling pip-20.2.4:\n",
      "      Successfully uninstalled pip-20.2.4\n",
      "Successfully installed pip-21.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Currently the notebook is using pip install, which would not be ideal in a production environment.\n",
    "# This is because the install changes the environment and the versions of libraries being installed are\n",
    "# not necessarily fixed, meaning the environment is not fixed and hence reproducibility is not guaranteed.\n",
    "# One could use requirements.txt, but this also does not necessarily fix things due to secondary dependencies.\n",
    "\n",
    "# Various solutions exist, but for rigorous work, Gradient allows the user to build a custom container\n",
    "# containing the correct dependencies, which removes the need for pip install.\n",
    "\n",
    "# Here, the container we use fixes versions, except for TFDS and TFRS, whose versions we therefore fix.\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install -q tensorflow-recommenders==0.4.0\n",
    "!pip install -q --upgrade tensorflow-datasets==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "951710e0-dcad-4a49-ad0e-ac4d3227671c",
     "kernelId": ""
    },
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# This is Python's function for more nicely or compactly printing variables or data\n",
    "import pprint\n",
    "\n",
    "# Python 3 allows hints on variable types to be given\n",
    "# Here they are used in the model class definitions\n",
    "from typing import Dict, Text\n",
    "\n",
    "# NumPy is used, e.g., for viewing the data in TensorFlow tensors\n",
    "# TensorFlow tensors are built on NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "# This allows simple inline plots of, e.g., model training history\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid') # Following TFRS tutorials\n",
    "\n",
    "# TensorFlow, TFDS, TFRS\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "351e3deb-5d51-4db2-a0e8-88e4e6501049",
     "kernelId": ""
    },
    "id": "ecPlfiYXJDQe"
   },
   "source": [
    "We can see some basic information about the versions of software that we are using. In principle, the container could be accessed to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "01073185-dfff-499a-ae9b-a123ac8f48b9",
     "kernelId": ""
    },
    "id": "Nc5Um6Y44D-Q",
    "outputId": "df8fe35b-e2e5-4a09-be4a-13c63c757ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.5\n",
      "Python version: 3.6.9\n",
      "TensorFlow version: 2.4.0\n",
      "TensorFlow Datasets version: 4.2.0\n",
      "TensorFlow Recommenders version: v0.4.0\n"
     ]
    }
   ],
   "source": [
    "print('NumPy version: {}'.format(np.__version__))\n",
    "print('Python version: {}'.format(platform.python_version()))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('TensorFlow Datasets version: {}'.format(tfds.__version__))\n",
    "print('TensorFlow Recommenders version: {}'.format(tfrs.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d9913690-51b7-479c-8b13-036b5d136f8e",
     "kernelId": ""
    },
    "id": "GJORoRytYAGI"
   },
   "source": [
    "We can see if GPUs, etc., are available, or just CPU. Here we do not currently specify devices other than the default, as the processing run is not large enough to require a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "f8318f17-c47b-47c8-a50a-4f23abf8e99e",
     "kernelId": ""
    },
    "id": "o914Boo2YDYz",
    "outputId": "1c553eac-8a74-4955-990e-6a6245fc14da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11116880676765012419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "aca0175a-a3f1-4788-9cec-b9fe76a4a9c0",
     "kernelId": ""
    },
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## 3: Preparing the dataset\n",
    "\n",
    "Load the MovieLens data from TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "01ab5e7e-104b-4139-8078-dcb3c0e30c7d",
     "kernelId": ""
    },
    "id": "aaQhqcLGP0jL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 4.70 MiB (download: 4.70 MiB, generated: 32.41 MiB, total: 37.10 MiB) to /root/tensorflow_datasets/movielens/100k-ratings/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3255d04c6ca949fba8dca13c54a5d952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c5859755424e0ea931c2a3ffd6e08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7949e5a980044e5db2b8698044520d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345c14be36064a8fbe548521780c9ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd95f5d1911415293a7d59af6b829ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c0b43291f94d4a8e4cae1e78224b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling movielens-train.tfrecord...:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /root/tensorflow_datasets/movielens/100k-ratings/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This loads the data from the official TensorFlow datasets repository\n",
    "# at https://www.tensorflow.org/datasets/catalog/movielens\n",
    "# The -ratings suffix indicates that we are loading the dataset with the\n",
    "# movies data joined to the ratings data\n",
    "\n",
    "ratings_raw = tfds.load('movielens/100k-ratings', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "f68becde-80ae-40c5-a75a-1e3ba526f11f",
     "kernelId": ""
    },
    "id": "X_sx4C_Bw4sc",
    "outputId": "aff47275-f87a-482c-eb1f-a8093d449c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {bucketized_user_age: (), movie_genres: (None,), movie_id: (), movie_title: (), raw_user_age: (), timestamp: (), user_gender: (), user_id: (), user_occupation_label: (), user_occupation_text: (), user_rating: (), user_zip_code: ()}, types: {bucketized_user_age: tf.float32, movie_genres: tf.int64, movie_id: tf.string, movie_title: tf.string, raw_user_age: tf.float32, timestamp: tf.int64, user_gender: tf.bool, user_id: tf.string, user_occupation_label: tf.int64, user_occupation_text: tf.string, user_rating: tf.float32, user_zip_code: tf.string}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is loaded as a TensorFlow PrefetchDataset\n",
    "ratings_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fd129db8-c8df-43cc-aabb-86e618e517c2",
     "kernelId": ""
    },
    "id": "9VReDbPf4QRU"
   },
   "source": [
    "Data science workflows, especially in the experimental and model training stage as here, should contain a strong component of viewing the actual data throughout the analysis. This is both for the understanding of the experimenter, other readers, and for sanity checking.\n",
    "\n",
    "Here we see that various columns (features) are available, including information about the user, the movie they watched, and outcomes such as the user's rating of the movie.\n",
    "\n",
    "It is important to distinguish between information that is available before a user watches a movie from that which is only available after, as the latter cannot be used as a feature for training a recommender model. This is because the data to be fed into it when it is deployed must be available before the user has watched the movie that is being recommended to them.\n",
    "\n",
    "In this case, the requirement manifests as the `user_rating` column being a training target and not a feature, and a timestamp column that should be normalized into something that is cyclical like a day of week / month / year, and not an absolute date. Such a date won't come around again in the future when the model has been deployed on unseen data.\n",
    "\n",
    "We also immediately see issues with the data that may manifest further along in the dataflow, such as some of the columns being byte-encoded (strings like `b'357'` instead of just `'357'`). If the setup of TensorFlow Serving plus the RESTful API is to be used for deployment, these will have to be converted to be able to be represented in JSON for passing to the model when it is deployed.\n",
    "\n",
    "The end-to-end mentality of having deployment in scope from the start, enabled by Gradient, has encouraged us to look for and notice these issues right here, rather than spending time training the model and only then noticing them. The latter approach could result in signficant wasted effort if it turns out that the deployment issues are not solvable.\n",
    "\n",
    "The top 2 rows of data are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "4cdf7d0d-e4fc-4f1a-b6b4-ae18fac1b47b",
     "kernelId": ""
    },
    "id": "JdNMayvVzhP9",
    "outputId": "2790ba40-5156-4601-aded-36340dc6db31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n",
      "{'bucketized_user_age': 25.0,\n",
      " 'movie_genres': array([ 4, 14]),\n",
      " 'movie_id': b'709',\n",
      " 'movie_title': b'Strictly Ballroom (1992)',\n",
      " 'raw_user_age': 32.0,\n",
      " 'timestamp': 875654590,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'92',\n",
      " 'user_occupation_label': 5,\n",
      " 'user_occupation_text': b'entertainment',\n",
      " 'user_rating': 2.0,\n",
      " 'user_zip_code': b'80525'}\n"
     ]
    }
   ],
   "source": [
    "# Just saying print(ratings) results in the output <PrefetchDataset shapes: ... as above\n",
    "# So the data is extracted from the TensorFlow tensor format using NumPy\n",
    "\n",
    "for x in ratings_raw.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "73b20e58-b9a5-4997-9044-c6a99b88c9a9",
     "kernelId": ""
    },
    "id": "Eo1v4Oac63Te"
   },
   "source": [
    "TensorFlow's `.map()` applies the function in the brackets to each element of a dataset, so with the lambda inline Python function we can reduce the data down to just the columns that we are going to use. Currently these are the movie title, the time of viewing, the user who viewed it, and their rating of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "de74ac2e-cca6-4c0a-82a9-39e029e2ace7",
     "kernelId": ""
    },
    "id": "fPH5ffpdw0RR"
   },
   "outputs": [],
   "source": [
    "ratings = ratings_raw.map(lambda x: {\n",
    "    'movie_title': x['movie_title'],\n",
    "    'timestamp': x['timestamp'],\n",
    "    'user_id': x['user_id'],\n",
    "    'user_rating': x['user_rating']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9bb019fa-669d-4d9b-8618-4474612a4eef",
     "kernelId": ""
    },
    "id": "Iu4XSa_G1nyN"
   },
   "source": [
    "We perform the canonical 80:20 random split of 80% training data and 20% testing data, with in turn 20% of the training data being used for model validation.\n",
    "\n",
    "As mentioned above, we want to avoid leakage of information from the testing set into the training and validation sets, so we split by timestamp. The testing data comes from later times than the training & validation data. Currently the timestamp used is still absolute rather than cyclic (day of week, month of year, etc.), but that would likely just dampen its utility as a feature, so long as the model is not overfitting to it.\n",
    "\n",
    "TensorFlow allows global and local random seeds to be set, which can ensure, e.g., that we get the same 80:20 split each time here.\n",
    "\n",
    "However, randomness remains in the machine learning models when they are run, which is harder to remove. We have not attempted to do so in this project so results may vary when the notebook is rerun, but they should show the same overall pattern, i.e., they are statistically reproducible even if not exactly reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "48387436-5687-4085-af88-8a6b4fcf48bd",
     "kernelId": ""
    },
    "id": "jjyIcUVEMmmP"
   },
   "outputs": [],
   "source": [
    "# Get times as a list so we can get the minimum and maximum time values\n",
    "# In the original data they are dictionaries, so a list is needed\n",
    "# Following the TFRS deep model tutorial (https://www.tensorflow.org/recommenders/examples/deep_recommenders)\n",
    "# a quick way to do this is\n",
    "\n",
    "timestamps = np.concatenate(list(ratings.map(lambda x: x['timestamp']).batch(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "a29e2097-97ef-4472-a6db-f45c19adcabe",
     "kernelId": ""
    },
    "id": "MD5dhCphMm2I",
    "outputId": "3c10d169-d485-44f7-9018-308fc8e68501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum time value = 874724710\n",
      "Maximum time value = 893286638\n"
     ]
    }
   ],
   "source": [
    "# Get minimum and maximum time values\n",
    "\n",
    "max_time = timestamps.max()\n",
    "min_time = timestamps.min()\n",
    "\n",
    "print('Minimum time value = {}'.format(min_time))\n",
    "print('Maximum time value = {}'.format(max_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "bdbcfdf8-d5dd-48a1-9c43-fea0ef95d11a",
     "kernelId": ""
    },
    "id": "BE16LGI8Mxry",
    "outputId": "0db255df-29ad-428c-8ea3-c5257029b1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60th percentile time = 885861866.8\n",
      "80th percentile time = 889574252.4\n"
     ]
    }
   ],
   "source": [
    "# Get 60th & 80th percentile times\n",
    "\n",
    "sixtieth_percentile = min_time + 0.6*(max_time - min_time)\n",
    "eightieth_percentile = min_time + 0.8*(max_time - min_time)\n",
    "\n",
    "print('60th percentile time = {}'.format(sixtieth_percentile))\n",
    "print('80th percentile time = {}'.format(eightieth_percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a560dec8-e102-4b2c-826f-44a4810be5f4",
     "kernelId": ""
    },
    "id": "ayX_o1YkMxx6"
   },
   "outputs": [],
   "source": [
    "# Filter original data so that\n",
    "\n",
    "# Training set <= 60th percentile time\n",
    "# 60th < Validation set <= 80th\n",
    "# Testing set > 80th\n",
    "\n",
    "train =      ratings.filter(lambda x: x['timestamp'] <= sixtieth_percentile)\n",
    "validation = ratings.filter(lambda x: x['timestamp'] > sixtieth_percentile and x['timestamp'] <= eightieth_percentile)\n",
    "test =       ratings.filter(lambda x: x['timestamp'] > eightieth_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "e2da07fd-01b4-46c3-885c-8e77d2aa3bf6",
     "kernelId": ""
    },
    "id": "Jwlwp7-MMx03",
    "outputId": "2c6df211-27f6-40e6-c891-aac0428ddd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set = 65336\n",
      "Number of rows in validation set = 15778\n",
      "Number of rows in testing set = 18886\n",
      "Total number of rows = 100000\n"
     ]
    }
   ],
   "source": [
    "# We are splitting on time percentiles and not row percentiles,\n",
    "# which means that we have assumed the times are roughly evenly distributed\n",
    "\n",
    "# So check the number of rows in the training, validation, and testing sets is as expected\n",
    "\n",
    "# We could also do row percentiles, which would involve sorting the data by time then shuffling after splitting\n",
    "# As written, the counting is a little slow, but .__len__() doesn't work on the FilterDataset from above\n",
    "\n",
    "# The lengths sum to the number of rows in the original data, currently 100,000, as expected\n",
    "\n",
    "ntimes_tr = 0\n",
    "ntimes_va = 0\n",
    "ntimes_te = 0\n",
    "\n",
    "for x in train.take(-1).as_numpy_iterator():\n",
    "    ntimes_tr += 1\n",
    "\n",
    "for x in validation.take(-1).as_numpy_iterator():\n",
    "    ntimes_va += 1\n",
    "\n",
    "for x in test.take(-1).as_numpy_iterator():\n",
    "    ntimes_te += 1\n",
    "    \n",
    "print('Number of rows in training set = {}'.format(ntimes_tr))\n",
    "print('Number of rows in validation set = {}'.format(ntimes_va))\n",
    "print('Number of rows in testing set = {}'.format(ntimes_te))\n",
    "print('Total number of rows = {}'.format(ntimes_tr + ntimes_va + ntimes_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c510727f-c6d9-4ca4-a55d-c7b6774a3eb1",
     "kernelId": ""
    },
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "# A validation set is created here because validation_split in model.fit() \n",
    "# is not supported for datasets - its input would have to be tensors\n",
    "# ( [1] ValueError: `validation_split` is only supported for Tensors or NumPy arrays, \n",
    "# found following types in the input: \n",
    "# [<class 'tensorflow.python.data.ops.dataset_ops.CacheDataset'>] )\n",
    "\n",
    "train = train.shuffle(ntimes_tr)\n",
    "validation = validation.shuffle(ntimes_va)\n",
    "test = test.shuffle(ntimes_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "430c558a-7986-484e-8afb-3d2827d7f961",
     "kernelId": ""
    },
    "id": "RNIIbzfYDMVt"
   },
   "source": [
    "We also need to extract from the data the list of unique user IDs and unique movie titles.\n",
    "\n",
    "This is because these variables are categorical, and when we use embedding vectors (see below), they map each category onto its own vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e0235d9d-17d6-40f4-a4a7-d02d4aadf6ac",
     "kernelId": ""
    },
    "id": "MKROCiPo_5LJ"
   },
   "outputs": [],
   "source": [
    "movie_titles = ratings.batch(1_000_000).map(lambda x: x['movie_title'])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "197d0fcf-6ffd-41c8-a50d-6f627e818c43",
     "kernelId": ""
    },
    "id": "6NfVEmLiz9jq"
   },
   "outputs": [],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2bab6eed-8340-4d89-8ad3-1af2483a5d5f",
     "kernelId": ""
    },
    "id": "4-Vj9nHb48pn"
   },
   "source": [
    "## 4: Build the recommender models\n",
    "\n",
    "As mentioned above, recommender systems are often composed of a retrieval model and a ranking model. We will be focusing on the ranking model.\n",
    "\n",
    "We will build two models:\n",
    "\n",
    " - Basic ranking\n",
    " - Tuned ranking\n",
    "\n",
    "and show that the tuned ranking model gives the best performance. This shows the importance of tuning and not just engineering a pipeline using a model off-the-shelf.\n",
    "\n",
    "Recommenders are more complex than basic supervised models, so in the hierarchy of increased flexibility but decreased simplicity or ease of use from the Keras Sequential API, through the Keras functional API, to full definition of model classes and subclasses, the latter approach is used. The classes don't have to be written entirely from scratch, however, as the TFRS library contains various convenience classes and functions, and higher level Keras models and layers can still be used when they fit the purpose.\n",
    "\n",
    "In these models, some of the feature preprocessing can be incorporated as part of the model. This reduces the chance of errors being introduced when it is deployed in production in a different place from where it was trained, because the preprocessing of data from the raw inputs to those correct for the model does not need to be duplicated.\n",
    "\n",
    "The various preprocessing steps and modeling components are combined into a recommender model that can then be trained. The model is described by a Python class that inherits from the TFRS base class.\n",
    "\n",
    "It includes:\n",
    "\n",
    " - Movie embeddings\n",
    " - User ID embeddings\n",
    " - Deep learning layer to compute the rankings\n",
    " - Task layer to compute mean squared error\n",
    " - The `call()` method\n",
    " - The `compute_loss()` method\n",
    "\n",
    "The movie and user ID *embeddings* are using this common method of reducing a column that contains a large number of unique categories to something more manageable. The raw categories get mapped onto integers (known as a vocabulary), which in turn are converted to embeddings. The embedding itself is a vector that represents the mapping from a space with many dimensions (the number of categories) to a continuous vector space with a much lower dimension, e.g., 32.\n",
    "\n",
    "The deep learning layer is a typical set of densely connected layers (every neuron connected to all the others) that allows an arbitrary nonlinear mapping between the inputs and outputs. Deep learning is typically more compute-intensive, but for ranking in a full production system only a small subset of the movies are being used, having been selected by the retrieval model, so this helps.\n",
    "\n",
    "The task layer computes mean squared error between a given ground truth target and the model's prediction. This feeds into `compute_loss()`. `Task` is a TFRS layer that is combining computing the loss, i.e., the measure by which the model training is iterated, and the metric, the measure by which the model performance is reported to the human user. In this case the loss is mean squared error and the metric is root mean squared error, so they are quite similar.\n",
    "\n",
    "The `compute_loss()` method measures how well the model is performing after each iteration of training. This is a built-in method to TFRS and is therefore automatically called during model training with a `tfrs.models.Model` class (the training loop).\n",
    "\n",
    "The `call()` method executes the various steps when the model is run, and is important for the model to be able to be saved for later deployment.\n",
    "\n",
    "The overall result is that for a given user ID and movie title fed to the model, the output is a prediction of what rating that user would give to that movie if they were to watch it. The movies with the highest predicted ratings therefore become the recommendations for that user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eebe086a-eda0-4da6-9e8f-d9ee03edc5ab",
     "kernelId": ""
    },
    "id": "2xiUI74SGklF"
   },
   "source": [
    "### 4.1: Basic ranking model\n",
    "\n",
    "The basic model shows what happens when a model is set up with some default parameters, without attempting to tune any of them.\n",
    "\n",
    "The model is similar to the one in the [TFRS multitask tutorial](https://www.tensorflow.org/recommenders/examples/multitask), here doing a single task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b7dde266-5c0e-4950-8521-2bdbbc5305d5",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class MovielensModelBasicRanking(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # The embeddings use Keras's preprocessing layers\n",
    "\n",
    "        # Embeddings for movies\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Embeddings for users\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Predicted ratings\n",
    "        # This is where deep learning is being used in the recommender system\n",
    "        # The predictions are output by the final layer, hence its size of 1\n",
    "\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Ranking is written as a TFRS task\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    # The call method allows the model to be run, and saved\n",
    "    # The embeddings are passed into the model\n",
    "    # The embeddings and predicted rating are returned\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        movie_embeddings = self.movie_model(features['movie_title'])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # This is the TFRS built-in method that computes the model loss function during training\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop('user_rating')\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        rating_loss = self.task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "\n",
    "        return rating_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "473fa8ca-a169-437a-9553-b69ba4e6a704",
     "kernelId": ""
    },
    "id": "SfAqxdgYH1Hl"
   },
   "source": [
    "As at the start of the dataflow, we should view the data at the training stage.\n",
    "\n",
    "The training data is quite similar to the original loaded data, now just movie title, timestamp, user ID, and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "1260d00f-c4ba-48d6-a63f-e307951d6a99",
     "kernelId": ""
    },
    "id": "X4wN-Oxqbqxa",
    "outputId": "bc70082f-74d0-4b6a-aeda-084cfbcb4d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: {movie_title: (), timestamp: (), user_id: (), user_rating: ()}, types: {movie_title: tf.string, timestamp: tf.int64, user_id: tf.string, user_rating: tf.float32}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format is now a TensorFlow ShuffleDataset\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "cf46ea32-3705-45ec-824d-2116a1f066d4",
     "kernelId": ""
    },
    "id": "7qByPgKIbjMH",
    "outputId": "1b202622-742c-47bc-a0b7-8115683aa920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': b'Jumanji (1995)',\n",
      " 'timestamp': 884673910,\n",
      " 'user_id': b'921',\n",
      " 'user_rating': 4.0}\n",
      "{'movie_title': b'Firm, The (1993)',\n",
      " 'timestamp': 883327040,\n",
      " 'user_id': b'60',\n",
      " 'user_rating': 4.0}\n",
      "{'movie_title': b'Leaving Las Vegas (1995)',\n",
      " 'timestamp': 878746982,\n",
      " 'user_id': b'150',\n",
      " 'user_rating': 5.0}\n"
     ]
    }
   ],
   "source": [
    "for x in train.take(3).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "13426db7-64d0-4683-b393-ee2eb4f7de89",
     "kernelId": ""
    },
    "id": "AdJbchJlqexl"
   },
   "source": [
    "The model performance, especially at scale, can be improved by caching the data into memory.\n",
    "\n",
    "It is also important that the data rows are in a random order. This is because many parts of machine learning algorithms are assuming that each data row is independent of those around it.\n",
    "\n",
    "An example of that is batching the data, which is also done here. Batching causes consecutive elements to be combined into batches, and so if there were, say, some periodicity in the data, it could interact with the batch size and produce highly non-random samples.\n",
    "\n",
    "Note that since a batch size may not divide perfectly into the number of rows in a dataset (or when data is being fed into the system a batch may not be full), its shape may not be known for every batch, and is therefore given as None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fd58bcc4-771f-4242-b956-9d40ad4ac216",
     "kernelId": ""
    },
    "id": "umCAS0aBdtYB"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(ntimes_tr).batch(8192).cache()\n",
    "cached_validation = validation.shuffle(ntimes_va).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "498396b5-e170-4b1b-8341-d42b627ed10c",
     "kernelId": ""
    },
    "id": "YO4SF6-Vqmi5"
   },
   "source": [
    "Since the actual data being fed into the model is the cached and batched set, this should be viewed too. We can see that it is now batched and the batches are formed by arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "03acff5d-761b-4531-8893-9cd10e3e4399",
     "kernelId": ""
    },
    "id": "aU6QtxRHbs3q",
    "outputId": "93f1e3b3-c4ea-4a63-bf65-246a46f87a90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset shapes: {movie_title: (None,), timestamp: (None,), user_id: (None,), user_rating: (None,)}, types: {movie_title: tf.string, timestamp: tf.int64, user_id: tf.string, user_rating: tf.float32}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape could be changed, e.g., from None to 8192 by adding drop_remainder=True to the .batch() line above\n",
    "cached_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "dec8245f-c409-4bdc-8376-7880600b2571",
     "kernelId": ""
    },
    "id": "dmjmVqnIbzxn",
    "outputId": "a26a618a-0bf8-4f9d-f4c9-e732ad0a55d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': array([b'Bridge on the River Kwai, The (1957)',\n",
      "       b'Manchurian Candidate, The (1962)', b'Mask, The (1994)', ...,\n",
      "       b'Seven (Se7en) (1995)', b'Cape Fear (1991)',\n",
      "       b'Butch Cassidy and the Sundance Kid (1969)'], dtype=object),\n",
      " 'timestamp': array([877816302, 877723882, 880607365, ..., 875335124, 882670057,\n",
      "       882374332]),\n",
      " 'user_id': array([b'594', b'16', b'244', ..., b'287', b'622', b'450'], dtype=object),\n",
      " 'user_rating': array([4., 5., 4., ..., 5., 3., 4.], dtype=float32)}\n",
      "{'movie_title': array([b'Shining, The (1980)', b'Contact (1997)',\n",
      "       b'Monty Python and the Holy Grail (1974)', ..., b'Bound (1996)',\n",
      "       b'Truth About Cats & Dogs, The (1996)', b'High School High (1996)'],\n",
      "      dtype=object),\n",
      " 'timestamp': array([877833632, 880353585, 882387773, ..., 875244331, 879647768,\n",
      "       883767108]),\n",
      " 'user_id': array([b'900', b'360', b'429', ..., b'221', b'417', b'795'], dtype=object),\n",
      " 'user_rating': array([2., 4., 5., ..., 5., 3., 3.], dtype=float32)}\n",
      "{'movie_title': array([b'Brady Bunch Movie, The (1995)', b'2001: A Space Odyssey (1968)',\n",
      "       b'Casino (1995)', ..., b'Mission: Impossible (1996)',\n",
      "       b'Alien (1979)', b'Psycho (1960)'], dtype=object),\n",
      " 'timestamp': array([884498292, 874873157, 877891575, ..., 879544027, 878769848,\n",
      "       875217033]),\n",
      " 'user_id': array([b'318', b'506', b'314', ..., b'277', b'82', b'130'], dtype=object),\n",
      " 'user_rating': array([3., 5., 3., ..., 3., 3., 5.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for x in cached_train.take(3).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f3922add-ae4d-4fec-812b-116844773b3b",
     "kernelId": ""
    },
    "id": "LsfOKQ30Iewj"
   },
   "source": [
    "#### 4.1.1: Train and evaluate the basic ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3e7a86f5-e4c5-4147-bc43-12ed8695bba8",
     "kernelId": ""
    },
    "id": "k_Pe7NpXq_r2"
   },
   "source": [
    "Train the model, outputting the accuracy on the training set and also on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8db3b98b-3ff4-402b-a45e-a8ceb7516819",
     "kernelId": ""
    },
    "id": "x7Kirx8U1Cww"
   },
   "outputs": [],
   "source": [
    "model_br = MovielensModelBasicRanking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "51648d7c-bebe-4299-b7b0-0dc8aa2d0855",
     "kernelId": ""
    },
    "id": "dzDwd1Rp1EbO"
   },
   "outputs": [],
   "source": [
    "model_br.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "3d784ba9-7faf-431b-927f-192109bc9195",
     "kernelId": ""
    },
    "id": "SieQYr041H90",
    "outputId": "5851b673-7e8a-4868-8de6-be40cd33efef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 38s 3s/step - root_mean_squared_error: 2.2442 - loss: 4.6202 - regularization_loss: 0.0000e+00 - total_loss: 4.6202 - val_root_mean_squared_error: 1.1901 - val_loss: 1.4150 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.4150\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 2s 199ms/step - root_mean_squared_error: 1.1857 - loss: 1.3937 - regularization_loss: 0.0000e+00 - total_loss: 1.3937 - val_root_mean_squared_error: 1.1451 - val_loss: 1.3040 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3040\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 2s 212ms/step - root_mean_squared_error: 1.1299 - loss: 1.2713 - regularization_loss: 0.0000e+00 - total_loss: 1.2713 - val_root_mean_squared_error: 1.1300 - val_loss: 1.2642 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2642\n"
     ]
    }
   ],
   "source": [
    "history_br = model_br.fit(cached_train, epochs=3, validation_data=cached_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ff62f927-0311-4688-a688-3ab2cf2d2ebf",
     "kernelId": ""
    },
    "id": "hI7yE0XerkjM"
   },
   "source": [
    "The full model history contains quite a lot of information:\n",
    "\n",
    " - Loss = the value of the loss function\n",
    " - Regularization loss = 0, since we are not applying regularization in the basic model\n",
    " - Root mean squared error = the model performance metric we are recording\n",
    " - Total loss = loss + regularization loss, so the same as loss here\n",
    " - The same four again, but for the validation set instead of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "3fec0c40-4aff-4848-92b4-0dfda46b7558",
     "kernelId": ""
    },
    "id": "aUk4iIRG0Uqf",
    "outputId": "f548679f-70b7-4510-ce02-4168f7778054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.37828528881073, 1.2994478940963745, 1.230413794517517],\n",
      " 'regularization_loss': [0, 0, 0],\n",
      " 'root_mean_squared_error': [2.2442262172698975,\n",
      "                             1.1856619119644165,\n",
      "                             1.1298515796661377],\n",
      " 'total_loss': [1.37828528881073, 1.2994478940963745, 1.230413794517517],\n",
      " 'val_loss': [1.4149616956710815, 1.3039723634719849, 1.264164924621582],\n",
      " 'val_regularization_loss': [0, 0, 0],\n",
      " 'val_root_mean_squared_error': [1.1901212930679321,\n",
      "                                 1.1451194286346436,\n",
      "                                 1.1300477981567383],\n",
      " 'val_total_loss': [1.4149616956710815, 1.3039723634719849, 1.264164924621582]}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(history_br.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "93b08052-d4c3-4050-83be-51ec659989ae",
     "kernelId": ""
    },
    "id": "Zs6U0oW5sVl8"
   },
   "source": [
    "We can report the most relevant numbers from the history, and make a simple plot of the tuning. Here we look at the value of the performance metric.\n",
    "\n",
    "The model has a performance of root mean squared error (RMSE) between predicted and true user ratings of movies of about 1.1, and the value is similar for training and validation, indicating that with the short training duration here the model has not overfit.\n",
    "\n",
    "A more sophisticated option than making these plots would be to load and use TensorBoard, but the overall conclusion drawn would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "4928953e-0599-4f5e-ac74-86b1eac94de7",
     "kernelId": ""
    },
    "id": "VY8Bt23jJAp1",
    "outputId": "13dbf653-a882-45cf-f0df-b225956c448c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from training: 1.13\n",
      "Root mean squared error in user rating from validation: 1.13\n"
     ]
    }
   ],
   "source": [
    "rmse_br = history_br.history['root_mean_squared_error'][-1]\n",
    "print(f'Root mean squared error in user rating from training: {rmse_br:.2f}')\n",
    "\n",
    "val_rmse_br = history_br.history['val_root_mean_squared_error'][-1]\n",
    "print(f'Root mean squared error in user rating from validation: {val_rmse_br:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "515e6d5f-66ff-4b90-8d24-67388ed8c951",
     "kernelId": ""
    },
    "id": "bFCCtUTyJnBF"
   },
   "outputs": [],
   "source": [
    "# This sets up the x axis of the plot\n",
    "num_validation_runs = len(history_br.history['root_mean_squared_error']) # Or val_ ; is same here\n",
    "\n",
    "# The TFRS tutorials include values of validation frequency >1 to accommodate training runs where it was set >1 for faster training\n",
    "# Here it is left as 1\n",
    "validation_freq = 1\n",
    "epochs = [(x + 1) * validation_freq for x in range(num_validation_runs)] # E.g., 3,6,9 ... if validation_freq = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "gradient": {
     "editing": false,
     "id": "d144c734-567c-493d-a91c-96f20bb6d9e1",
     "kernelId": ""
    },
    "id": "FOZthVRbJ5iW",
    "outputId": "884a1cdc-52e7-4edb-f04f-523c3fd64fdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9aa03de128>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple plot with Matplotlib\n",
    "plt.plot(epochs, history_br.history['root_mean_squared_error'], label='Training')\n",
    "plt.plot(epochs, history_br.history['val_root_mean_squared_error'], label='Validation')\n",
    "plt.title('Root mean squared error in user rating vs. training epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Root mean squared error in user rating')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8c965473-5607-4009-adc9-428cb402fbc8",
     "kernelId": ""
    },
    "id": "2n7xDu0C1JCg"
   },
   "source": [
    "We can see the model architecture via `.summary()`, showing the deep learning layers. Even for this small model, the number of parameters is over 100,000, which is greater than the number of movies in the dataset. This shows the importance of setting up the model to not overfit when trained for longer, which we will do in the tuned model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "3e2352bc-7502-450c-b1d4-68978ec8c04d",
     "kernelId": ""
    },
    "id": "v44Elq721cSy",
    "outputId": "a2fb073d-eae5-4c62-954f-b3a17b6d42eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movielens_model_basic_ranking\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 32)                53280     \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32)                30208     \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 33153     \n",
      "_________________________________________________________________\n",
      "ranking (Ranking)            multiple                  2         \n",
      "=================================================================\n",
      "Total params: 116,643\n",
      "Trainable params: 116,641\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_br.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a23c6ade-3262-40a4-a95d-a9a0288002cc",
     "kernelId": ""
    },
    "id": "XoBOlpc4-_hG"
   },
   "source": [
    "The model's performance can be measured on unseen test data for which what the user did in fact rate the movie (the ground truth) is still available.\n",
    "\n",
    "It is important that the test data is not used as part of the model training or validation, either directly (overlap between training and testing data), or indirectly (performance on testing data being used to influence subsequent training runs).\n",
    "\n",
    "Both of these would produce a result biased high in performance compared to expected performance on new unseen data when the model is deployed in production.\n",
    "\n",
    "As expected following the validation, the RMSE on the unseen testing set is also approximately 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "4ebfbe03-ef3e-412c-b34a-e8a85be9e0db",
     "kernelId": ""
    },
    "id": "bt8TsSix1cXX",
    "outputId": "0f7c32fe-4a23-472b-db4c-6068fd087cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 15s 77ms/step - root_mean_squared_error: 1.1209 - loss: 1.2642 - regularization_loss: 0.0000e+00 - total_loss: 1.2642\n"
     ]
    }
   ],
   "source": [
    "eval_br = model_br.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "9ceb9623-8856-41f4-89ce-b0027733d2df",
     "kernelId": ""
    },
    "id": "Pp84Btjd3Ovt",
    "outputId": "766d686e-80a5-4211-ee8a-607345432fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.120877981185913,\n",
       " 'loss': 1.2902494668960571,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.2902494668960571}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "eafab91a-2d7e-40a7-a5c8-4976a9041746",
     "kernelId": ""
    },
    "id": "kHu2-zfTKL34",
    "outputId": "9eb7222a-45ee-42a8-cd06-8172078e06c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from evaluation: 1.12\n"
     ]
    }
   ],
   "source": [
    "rmse_eval_br = eval_br['root_mean_squared_error']\n",
    "print(f'Root mean squared error in user rating from evaluation: {rmse_eval_br:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bc608826-156e-4e90-9c39-43cd6f3ccd37",
     "kernelId": ""
    },
    "id": "rWqyrily-JE6"
   },
   "source": [
    "Calling `.predict()` on the model, i.e., sending it data from the testing set in the same manner as new data would be sent to it when deployed, yields the user & movie embeddings for each new data point, and the predicted user ratings for those data points.\n",
    "\n",
    "Here the testing data still has ground truth user ratings that these predictions can be compared to (as in evaluate, above), but of course in production the return will be just the predicted ratings (and embeddings, in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "a077da3b-683b-427d-ad4b-ce7b432d7566",
     "kernelId": ""
    },
    "id": "eA7_9Lgi1cav",
    "outputId": "5a39f4c6-50c2-4643-cf8e-082b4e215c8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.03964598, -0.03422852,  0.04101512, ...,  0.00219501,\n",
       "          0.01934109, -0.01082342],\n",
       "        [-0.04646686, -0.00338645, -0.03383372, ...,  0.00051974,\n",
       "          0.02353701, -0.02411617],\n",
       "        [ 0.0054427 ,  0.04025881, -0.01628982, ...,  0.0322423 ,\n",
       "          0.01506004, -0.00209037],\n",
       "        ...,\n",
       "        [-0.0052987 ,  0.03847931, -0.03077863, ..., -0.03886672,\n",
       "          0.01689538, -0.01025091],\n",
       "        [-0.01464785, -0.01887847,  0.01075666, ..., -0.02833327,\n",
       "          0.02839414,  0.02894009],\n",
       "        [-0.0038248 , -0.03222672, -0.0437872 , ...,  0.01673976,\n",
       "         -0.04672277, -0.00335848]], dtype=float32),\n",
       " array([[ 0.0146039 , -0.02525433,  0.0283344 , ...,  0.01268173,\n",
       "          0.03344029, -0.00479257],\n",
       "        [-0.03651332, -0.01501979, -0.04718434, ...,  0.02178776,\n",
       "          0.01717076,  0.01619942],\n",
       "        [-0.01173977,  0.03963666, -0.00660629, ..., -0.01299132,\n",
       "         -0.03898761, -0.03248708],\n",
       "        ...,\n",
       "        [-0.01738477,  0.03932676,  0.03252422, ..., -0.01226671,\n",
       "         -0.03862289,  0.00027237],\n",
       "        [ 0.00951628,  0.00578687, -0.0146631 , ...,  0.0293301 ,\n",
       "          0.02951677,  0.02755978],\n",
       "        [-0.0288859 , -0.03771396, -0.01316686, ...,  0.02185896,\n",
       "         -0.00954689, -0.02850651]], dtype=float32),\n",
       " array([[3.4749115],\n",
       "        [3.3650532],\n",
       "        [3.3401022],\n",
       "        ...,\n",
       "        [3.4586565],\n",
       "        [3.4256346],\n",
       "        [3.431732 ]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As written, the model prediction returns both the embeddings and predicted ratings\n",
    "model_br.predict(cached_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c5106c30-dd8d-410c-bc86-e33023696c9e",
     "kernelId": ""
    },
    "id": "5CNURtsNIfC2"
   },
   "source": [
    "### 4.2: Tuned ranking model\n",
    "\n",
    "For most machine learning models, a model that has not had its hyperparameters tuned is unlikely to be giving best performance. It would be a bit like choosing random clothes from a store instead of clothes that are your size.\n",
    "\n",
    "The combination of being able to be tuned to higher performance, and the ability to easily add new training set features of many different kinds (categorical, numerical, text, time series, etc.) is what enables deep learning (or other nonlinear ML such as decision trees) to outperform classical non-ML methods on complex data. As written, the deep learning layers component of the model can be whatever arbitrary set of layers, so long as it outputs a single rating at the end.\n",
    "\n",
    "Here we perform some basic tuning on the neural network layer by training it for more epochs and allowing its initial learning rate to vary. We also add regularization to help avoid overfitting that could result from longer training.\n",
    "\n",
    "For more extensive tuning, other parameters can be tuned similarly, including within the network, e.g., size & number of layers, and within the whole model, such as the number of dimensions in the embeddings.\n",
    "\n",
    "If one plans to do more extensive tuning, then for a recommender system like this one, it also makes sense to include more features, such as user age, do more feature engineering, such as cyclic and not absolute times like day of week, and to build more complex models like multitask and deep cross networks as in the TFRS tutorials. To keep this showcase to a manageable length, we do not attempt all of that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6ce6d1c1-01d5-4ffc-853c-125a61f0da25",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# This model is similar to the basic model, but L2 regularization has been added\n",
    "\n",
    "class MovielensModelTunedRanking(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Regularization is added here\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        movie_embeddings = self.movie_model(features['movie_title'])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop('user_rating')\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        rating_loss = self.task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "\n",
    "        return rating_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d08c49a3-cac2-429b-83b7-6e013fb0ea92",
     "kernelId": ""
    },
    "id": "HVp_55ctAF48"
   },
   "source": [
    "When tuning hyperparameters using the grid approach, it is common to test a range of values across a logarithmic scale, then fine-tune by using a linear scale in the range suggested to be best by the logarithmic scale. (For example, try learning rates of 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, and 1, and if the performance is best for 0.1, then try 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, and 0.15.)\n",
    "\n",
    "Here we only show a small number of values to avoid excessive processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "faa9dba0-307a-4480-899a-bcd49aa093cf",
     "kernelId": ""
    },
    "id": "0WH4-3S7HOCC"
   },
   "source": [
    "Let's set the values we are tuning so they are not hidden in the calls to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2ff69570-3732-40ae-a648-d3af648c7b0d",
     "kernelId": ""
    },
    "id": "o2fF4CN5HUj0"
   },
   "outputs": [],
   "source": [
    "learning_rates_logarithmic = [0.001, 0.01, 0.1, 1]\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "254d8530-29be-4139-8c7c-7f72642192d7",
     "kernelId": ""
    },
    "id": "jvxCoGSDHxb-"
   },
   "source": [
    "Run the logarithmic grid. As with the basic model, the indicator of performance is the RMSE error, shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "6ae980f3-c158-49a3-bfc4-cd93a214cc79",
     "kernelId": ""
    },
    "id": "IIWlPgqD4Hr6",
    "outputId": "e051920a-cec9-4b54-d688-68dcf6a6c627",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.001\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 4s 274ms/step - root_mean_squared_error: 3.6710 - loss: 13.4524 - regularization_loss: 2.0560 - total_loss: 15.5084 - val_root_mean_squared_error: 3.5643 - val_loss: 12.7940 - val_regularization_loss: 2.0550 - val_total_loss: 14.8490\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 2s 285ms/step - root_mean_squared_error: 3.6315 - loss: 13.1681 - regularization_loss: 2.0541 - total_loss: 15.2222 - val_root_mean_squared_error: 3.5305 - val_loss: 12.5533 - val_regularization_loss: 2.0531 - val_total_loss: 14.6065\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 2s 198ms/step - root_mean_squared_error: 3.5991 - loss: 12.9350 - regularization_loss: 2.0523 - total_loss: 14.9873 - val_root_mean_squared_error: 3.5004 - val_loss: 12.3406 - val_regularization_loss: 2.0514 - val_total_loss: 14.3920\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 1s 187ms/step - root_mean_squared_error: 3.5696 - loss: 12.7245 - regularization_loss: 2.0505 - total_loss: 14.7750 - val_root_mean_squared_error: 3.4723 - val_loss: 12.1441 - val_regularization_loss: 2.0496 - val_total_loss: 14.1938\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 2s 210ms/step - root_mean_squared_error: 3.5417 - loss: 12.5272 - regularization_loss: 2.0488 - total_loss: 14.5760 - val_root_mean_squared_error: 3.4454 - val_loss: 11.9572 - val_regularization_loss: 2.0480 - val_total_loss: 14.0051\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 2s 215ms/step - root_mean_squared_error: 3.5148 - loss: 12.3375 - regularization_loss: 2.0472 - total_loss: 14.3847 - val_root_mean_squared_error: 3.4191 - val_loss: 11.7758 - val_regularization_loss: 2.0464 - val_total_loss: 13.8221\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 2s 202ms/step - root_mean_squared_error: 3.4883 - loss: 12.1522 - regularization_loss: 2.0456 - total_loss: 14.1978 - val_root_mean_squared_error: 3.3930 - val_loss: 11.5973 - val_regularization_loss: 2.0448 - val_total_loss: 13.6421\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 2s 202ms/step - root_mean_squared_error: 3.4620 - loss: 11.9688 - regularization_loss: 2.0441 - total_loss: 14.0129 - val_root_mean_squared_error: 3.3669 - val_loss: 11.4200 - val_regularization_loss: 2.0433 - val_total_loss: 13.4633\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 2s 200ms/step - root_mean_squared_error: 3.4355 - loss: 11.7861 - regularization_loss: 2.0426 - total_loss: 13.8288 - val_root_mean_squared_error: 3.3406 - val_loss: 11.2428 - val_regularization_loss: 2.0419 - val_total_loss: 13.2846\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 2s 201ms/step - root_mean_squared_error: 3.4087 - loss: 11.6031 - regularization_loss: 2.0412 - total_loss: 13.6443 - val_root_mean_squared_error: 3.3140 - val_loss: 11.0648 - val_regularization_loss: 2.0405 - val_total_loss: 13.1053\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 2s 210ms/step - root_mean_squared_error: 3.3816 - loss: 11.4189 - regularization_loss: 2.0398 - total_loss: 13.4588 - val_root_mean_squared_error: 3.2870 - val_loss: 10.8857 - val_regularization_loss: 2.0392 - val_total_loss: 12.9248\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 3s 326ms/step - root_mean_squared_error: 3.3540 - loss: 11.2332 - regularization_loss: 2.0385 - total_loss: 13.2718 - val_root_mean_squared_error: 3.2595 - val_loss: 10.7048 - val_regularization_loss: 2.0379 - val_total_loss: 12.7427\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 3s 357ms/step - root_mean_squared_error: 3.3260 - loss: 11.0456 - regularization_loss: 2.0373 - total_loss: 13.0829 - val_root_mean_squared_error: 3.2314 - val_loss: 10.5221 - val_regularization_loss: 2.0366 - val_total_loss: 12.5587\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 3s 355ms/step - root_mean_squared_error: 3.2973 - loss: 10.8559 - regularization_loss: 2.0360 - total_loss: 12.8919 - val_root_mean_squared_error: 3.2029 - val_loss: 10.3372 - val_regularization_loss: 2.0354 - val_total_loss: 12.3726\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 3s 371ms/step - root_mean_squared_error: 3.2681 - loss: 10.6638 - regularization_loss: 2.0349 - total_loss: 12.6987 - val_root_mean_squared_error: 3.1737 - val_loss: 10.1501 - val_regularization_loss: 2.0343 - val_total_loss: 12.1844\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 3s 410ms/step - root_mean_squared_error: 3.2382 - loss: 10.4694 - regularization_loss: 2.0337 - total_loss: 12.5032 - val_root_mean_squared_error: 3.1439 - val_loss: 9.9609 - val_regularization_loss: 2.0331 - val_total_loss: 11.9940\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 3s 357ms/step - root_mean_squared_error: 3.2077 - loss: 10.2727 - regularization_loss: 2.0326 - total_loss: 12.3053 - val_root_mean_squared_error: 3.1134 - val_loss: 9.7695 - val_regularization_loss: 2.0321 - val_total_loss: 11.8015\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 3s 360ms/step - root_mean_squared_error: 3.1765 - loss: 10.0737 - regularization_loss: 2.0316 - total_loss: 12.1052 - val_root_mean_squared_error: 3.0823 - val_loss: 9.5759 - val_regularization_loss: 2.0310 - val_total_loss: 11.6069\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 3s 398ms/step - root_mean_squared_error: 3.1447 - loss: 9.8724 - regularization_loss: 2.0305 - total_loss: 11.9029 - val_root_mean_squared_error: 3.0506 - val_loss: 9.3804 - val_regularization_loss: 2.0300 - val_total_loss: 11.4104\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 3s 381ms/step - root_mean_squared_error: 3.1122 - loss: 9.6690 - regularization_loss: 2.0295 - total_loss: 11.6985 - val_root_mean_squared_error: 3.0183 - val_loss: 9.1829 - val_regularization_loss: 2.0290 - val_total_loss: 11.2120\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 3s 373ms/step - root_mean_squared_error: 3.0791 - loss: 9.4637 - regularization_loss: 2.0286 - total_loss: 11.4922 - val_root_mean_squared_error: 2.9853 - val_loss: 8.9838 - val_regularization_loss: 2.0281 - val_total_loss: 11.0119\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 3s 396ms/step - root_mean_squared_error: 3.0452 - loss: 9.2566 - regularization_loss: 2.0276 - total_loss: 11.2843 - val_root_mean_squared_error: 2.9517 - val_loss: 8.7833 - val_regularization_loss: 2.0272 - val_total_loss: 10.8104\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 3s 340ms/step - root_mean_squared_error: 3.0108 - loss: 9.0481 - regularization_loss: 2.0267 - total_loss: 11.0748 - val_root_mean_squared_error: 2.9175 - val_loss: 8.5815 - val_regularization_loss: 2.0263 - val_total_loss: 10.6078\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 3s 359ms/step - root_mean_squared_error: 2.9758 - loss: 8.8383 - regularization_loss: 2.0259 - total_loss: 10.8642 - val_root_mean_squared_error: 2.8827 - val_loss: 8.3788 - val_regularization_loss: 2.0254 - val_total_loss: 10.4043\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 3s 319ms/step - root_mean_squared_error: 2.9402 - loss: 8.6277 - regularization_loss: 2.0250 - total_loss: 10.6527 - val_root_mean_squared_error: 2.8475 - val_loss: 8.1756 - val_regularization_loss: 2.0246 - val_total_loss: 10.2002\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 3s 344ms/step - root_mean_squared_error: 2.9040 - loss: 8.4166 - regularization_loss: 2.0242 - total_loss: 10.4408 - val_root_mean_squared_error: 2.8117 - val_loss: 7.9722 - val_regularization_loss: 2.0238 - val_total_loss: 9.9960\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 3s 369ms/step - root_mean_squared_error: 2.8674 - loss: 8.2053 - regularization_loss: 2.0234 - total_loss: 10.2287 - val_root_mean_squared_error: 2.7755 - val_loss: 7.7689 - val_regularization_loss: 2.0230 - val_total_loss: 9.7919\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 3s 360ms/step - root_mean_squared_error: 2.8303 - loss: 7.9942 - regularization_loss: 2.0227 - total_loss: 10.0168 - val_root_mean_squared_error: 2.7390 - val_loss: 7.5660 - val_regularization_loss: 2.0223 - val_total_loss: 9.5883\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 2s 315ms/step - root_mean_squared_error: 2.7929 - loss: 7.7836 - regularization_loss: 2.0219 - total_loss: 9.8055 - val_root_mean_squared_error: 2.7020 - val_loss: 7.3639 - val_regularization_loss: 2.0216 - val_total_loss: 9.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "8/8 [==============================] - 3s 356ms/step - root_mean_squared_error: 2.7551 - loss: 7.5739 - regularization_loss: 2.0212 - total_loss: 9.5951 - val_root_mean_squared_error: 2.6648 - val_loss: 7.1630 - val_regularization_loss: 2.0208 - val_total_loss: 9.1839\n",
      "Learning rate = 0.01\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 7s 476ms/step - root_mean_squared_error: 3.4480 - loss: 11.6461 - regularization_loss: 2.0333 - total_loss: 13.6794 - val_root_mean_squared_error: 2.9485 - val_loss: 8.7637 - val_regularization_loss: 2.0254 - val_total_loss: 10.7891\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 3s 358ms/step - root_mean_squared_error: 2.5971 - loss: 6.4708 - regularization_loss: 2.0222 - total_loss: 8.4930 - val_root_mean_squared_error: 1.8883 - val_loss: 3.5994 - val_regularization_loss: 2.0204 - val_total_loss: 5.6198\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 2s 313ms/step - root_mean_squared_error: 1.5748 - loss: 2.3776 - regularization_loss: 2.0190 - total_loss: 4.3966 - val_root_mean_squared_error: 1.2034 - val_loss: 1.4490 - val_regularization_loss: 2.0159 - val_total_loss: 3.4649\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 3s 342ms/step - root_mean_squared_error: 1.1607 - loss: 1.3379 - regularization_loss: 2.0095 - total_loss: 3.3474 - val_root_mean_squared_error: 1.1334 - val_loss: 1.2740 - val_regularization_loss: 2.0013 - val_total_loss: 3.2753\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 3s 329ms/step - root_mean_squared_error: 1.1235 - loss: 1.2610 - regularization_loss: 1.9924 - total_loss: 3.2533 - val_root_mean_squared_error: 1.1336 - val_loss: 1.2725 - val_regularization_loss: 1.9826 - val_total_loss: 3.2551\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 3s 329ms/step - root_mean_squared_error: 1.1203 - loss: 1.2542 - regularization_loss: 1.9733 - total_loss: 3.2275 - val_root_mean_squared_error: 1.1335 - val_loss: 1.2721 - val_regularization_loss: 1.9633 - val_total_loss: 3.2354\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 3s 359ms/step - root_mean_squared_error: 1.1185 - loss: 1.2502 - regularization_loss: 1.9540 - total_loss: 3.2042 - val_root_mean_squared_error: 1.1331 - val_loss: 1.2710 - val_regularization_loss: 1.9441 - val_total_loss: 3.2151\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 2s 300ms/step - root_mean_squared_error: 1.1168 - loss: 1.2464 - regularization_loss: 1.9349 - total_loss: 3.1813 - val_root_mean_squared_error: 1.1326 - val_loss: 1.2699 - val_regularization_loss: 1.9251 - val_total_loss: 3.1950\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 3s 344ms/step - root_mean_squared_error: 1.1151 - loss: 1.2427 - regularization_loss: 1.9161 - total_loss: 3.1587 - val_root_mean_squared_error: 1.1321 - val_loss: 1.2687 - val_regularization_loss: 1.9064 - val_total_loss: 3.1751\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 3s 369ms/step - root_mean_squared_error: 1.1135 - loss: 1.2390 - regularization_loss: 1.8974 - total_loss: 3.1364 - val_root_mean_squared_error: 1.1316 - val_loss: 1.2676 - val_regularization_loss: 1.8878 - val_total_loss: 3.1554\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 3s 330ms/step - root_mean_squared_error: 1.1118 - loss: 1.2352 - regularization_loss: 1.8789 - total_loss: 3.1142 - val_root_mean_squared_error: 1.1311 - val_loss: 1.2665 - val_regularization_loss: 1.8695 - val_total_loss: 3.1360\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 3s 357ms/step - root_mean_squared_error: 1.1101 - loss: 1.2315 - regularization_loss: 1.8607 - total_loss: 3.0922 - val_root_mean_squared_error: 1.1306 - val_loss: 1.2654 - val_regularization_loss: 1.8513 - val_total_loss: 3.1167\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 3s 373ms/step - root_mean_squared_error: 1.1084 - loss: 1.2277 - regularization_loss: 1.8427 - total_loss: 3.0704 - val_root_mean_squared_error: 1.1301 - val_loss: 1.2642 - val_regularization_loss: 1.8334 - val_total_loss: 3.0977\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 3s 346ms/step - root_mean_squared_error: 1.1067 - loss: 1.2239 - regularization_loss: 1.8248 - total_loss: 3.0487 - val_root_mean_squared_error: 1.1296 - val_loss: 1.2631 - val_regularization_loss: 1.8157 - val_total_loss: 3.0788\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 3s 384ms/step - root_mean_squared_error: 1.1049 - loss: 1.2200 - regularization_loss: 1.8072 - total_loss: 3.0272 - val_root_mean_squared_error: 1.1291 - val_loss: 1.2620 - val_regularization_loss: 1.7982 - val_total_loss: 3.0602\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 2s 328ms/step - root_mean_squared_error: 1.1031 - loss: 1.2160 - regularization_loss: 1.7898 - total_loss: 3.0058 - val_root_mean_squared_error: 1.1286 - val_loss: 1.2609 - val_regularization_loss: 1.7808 - val_total_loss: 3.0417\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 3s 337ms/step - root_mean_squared_error: 1.1012 - loss: 1.2119 - regularization_loss: 1.7726 - total_loss: 2.9845 - val_root_mean_squared_error: 1.1280 - val_loss: 1.2597 - val_regularization_loss: 1.7637 - val_total_loss: 3.0234\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 3s 369ms/step - root_mean_squared_error: 1.0993 - loss: 1.2078 - regularization_loss: 1.7556 - total_loss: 2.9634 - val_root_mean_squared_error: 1.1275 - val_loss: 1.2586 - val_regularization_loss: 1.7468 - val_total_loss: 3.0054\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 3s 345ms/step - root_mean_squared_error: 1.0974 - loss: 1.2035 - regularization_loss: 1.7387 - total_loss: 2.9423 - val_root_mean_squared_error: 1.1270 - val_loss: 1.2574 - val_regularization_loss: 1.7301 - val_total_loss: 2.9874\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 3s 413ms/step - root_mean_squared_error: 1.0954 - loss: 1.1992 - regularization_loss: 1.7221 - total_loss: 2.9213 - val_root_mean_squared_error: 1.1264 - val_loss: 1.2562 - val_regularization_loss: 1.7135 - val_total_loss: 2.9697\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 3s 356ms/step - root_mean_squared_error: 1.0933 - loss: 1.1947 - regularization_loss: 1.7057 - total_loss: 2.9004 - val_root_mean_squared_error: 1.1258 - val_loss: 1.2549 - val_regularization_loss: 1.6972 - val_total_loss: 2.9521\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 3s 341ms/step - root_mean_squared_error: 1.0912 - loss: 1.1901 - regularization_loss: 1.6894 - total_loss: 2.8796 - val_root_mean_squared_error: 1.1253 - val_loss: 1.2537 - val_regularization_loss: 1.6811 - val_total_loss: 2.9347\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 3s 382ms/step - root_mean_squared_error: 1.0891 - loss: 1.1855 - regularization_loss: 1.6733 - total_loss: 2.8588 - val_root_mean_squared_error: 1.1247 - val_loss: 1.2524 - val_regularization_loss: 1.6651 - val_total_loss: 2.9175\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 3s 363ms/step - root_mean_squared_error: 1.0869 - loss: 1.1807 - regularization_loss: 1.6575 - total_loss: 2.8382 - val_root_mean_squared_error: 1.1241 - val_loss: 1.2511 - val_regularization_loss: 1.6493 - val_total_loss: 2.9004\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 3s 357ms/step - root_mean_squared_error: 1.0846 - loss: 1.1758 - regularization_loss: 1.6418 - total_loss: 2.8176 - val_root_mean_squared_error: 1.1234 - val_loss: 1.2497 - val_regularization_loss: 1.6337 - val_total_loss: 2.8834\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 3s 345ms/step - root_mean_squared_error: 1.0823 - loss: 1.1709 - regularization_loss: 1.6263 - total_loss: 2.7971 - val_root_mean_squared_error: 1.1228 - val_loss: 1.2483 - val_regularization_loss: 1.6183 - val_total_loss: 2.8666\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 3s 358ms/step - root_mean_squared_error: 1.0800 - loss: 1.1659 - regularization_loss: 1.6109 - total_loss: 2.7768 - val_root_mean_squared_error: 1.1221 - val_loss: 1.2469 - val_regularization_loss: 1.6030 - val_total_loss: 2.8500\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 3s 343ms/step - root_mean_squared_error: 1.0776 - loss: 1.1608 - regularization_loss: 1.5958 - total_loss: 2.7565 - val_root_mean_squared_error: 1.1215 - val_loss: 1.2455 - val_regularization_loss: 1.5880 - val_total_loss: 2.8334\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 342ms/step - root_mean_squared_error: 1.0752 - loss: 1.1556 - regularization_loss: 1.5808 - total_loss: 2.7364 - val_root_mean_squared_error: 1.1208 - val_loss: 1.2440 - val_regularization_loss: 1.5731 - val_total_loss: 2.8171\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 2s 300ms/step - root_mean_squared_error: 1.0728 - loss: 1.1504 - regularization_loss: 1.5660 - total_loss: 2.7164 - val_root_mean_squared_error: 1.1200 - val_loss: 1.2424 - val_regularization_loss: 1.5584 - val_total_loss: 2.8008\n",
      "Learning rate = 0.1\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 7s 459ms/step - root_mean_squared_error: 2.3946 - loss: 5.2584 - regularization_loss: 1.9514 - total_loss: 7.2098 - val_root_mean_squared_error: 1.1550 - val_loss: 1.3157 - val_regularization_loss: 1.8641 - val_total_loss: 3.1798\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 3s 370ms/step - root_mean_squared_error: 1.1206 - loss: 1.2539 - regularization_loss: 1.7756 - total_loss: 3.0295 - val_root_mean_squared_error: 1.1333 - val_loss: 1.2704 - val_regularization_loss: 1.6868 - val_total_loss: 2.9572\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 2s 326ms/step - root_mean_squared_error: 1.1118 - loss: 1.2347 - regularization_loss: 1.6085 - total_loss: 2.8432 - val_root_mean_squared_error: 1.1309 - val_loss: 1.2651 - val_regularization_loss: 1.5288 - val_total_loss: 2.7940\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 3s 398ms/step - root_mean_squared_error: 1.1025 - loss: 1.2137 - regularization_loss: 1.4586 - total_loss: 2.6724 - val_root_mean_squared_error: 1.1282 - val_loss: 1.2592 - val_regularization_loss: 1.3872 - val_total_loss: 2.6464\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 3s 350ms/step - root_mean_squared_error: 1.0900 - loss: 1.1862 - regularization_loss: 1.3244 - total_loss: 2.5106 - val_root_mean_squared_error: 1.1248 - val_loss: 1.2518 - val_regularization_loss: 1.2605 - val_total_loss: 2.5123\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 3s 453ms/step - root_mean_squared_error: 1.0747 - loss: 1.1531 - regularization_loss: 1.2044 - total_loss: 2.3575 - val_root_mean_squared_error: 1.1205 - val_loss: 1.2426 - val_regularization_loss: 1.1473 - val_total_loss: 2.3898\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 3s 354ms/step - root_mean_squared_error: 1.0581 - loss: 1.1180 - regularization_loss: 1.0970 - total_loss: 2.2150 - val_root_mean_squared_error: 1.1152 - val_loss: 1.2311 - val_regularization_loss: 1.0458 - val_total_loss: 2.2769\n",